{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na6nU1sW_IFY"
   },
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1730797804196,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "PDt3AWuCbwHK"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import dill\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM_7OwXM0wg6"
   },
   "source": [
    "# SETUP CONSTANTS\n",
    "\n",
    "* Pada bagian ini, kita akan mendefinisikan beberapa konstanta yang penting untuk proses pemrosesan data dan pelatihan model.\n",
    "* Konstanta ini akan membantu kita dalam mengatur jalur folder dataset, pola ekstensi file gambar yang akan dikumpulkan, dan folder mana saja yang harus diakses.\n",
    "* Nantinya, konstanta-konstanta ini akan digunakan di berbagai bagian kode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTyZTPqu2SvT"
   },
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_zip(url, save_dir, extract_dir, filename=\"dataset.zip\", chunk_size=1024, is_file_removed=True):\n",
    "    \"\"\"\n",
    "    Mengunduh file zip dari URL dan mengekstraknya ke direktori tertentu hanya jika belum ada hasil ekstrak.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL file zip yang akan diunduh.\n",
    "        save_dir (str): Direktori tempat menyimpan file zip.\n",
    "        extract_dir (str): Direktori tujuan untuk mengekstrak file zip.\n",
    "        filename (str, optional): Nama file zip yang disimpan. Default \"dataset.zip\".\n",
    "        chunk_size (int, optional): Ukuran chunk untuk unduhan. Default 1024 (1 KB).\n",
    "        is_file_removed (bool, optional): Hapus file zip setelah ekstraksi. Default True.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Jika ada error saat mengunduh atau mengekstrak file.\n",
    "    \"\"\"\n",
    "    # Memastikan direktori penyimpanan dan ekstrak ada\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    # Path file zip yang akan disimpan\n",
    "    file_path = os.path.join(save_dir, filename)\n",
    "\n",
    "    # Pengecekan apakah direktori ekstrak sudah berisi file\n",
    "    if os.listdir(extract_dir):  \n",
    "        print(\"File sudah diekstrak sebelumnya. Tidak ada tindakan lebih lanjut.\")\n",
    "        return  # Keluar dari fungsi jika file sudah diekstrak\n",
    "\n",
    "    # Jika belum ada hasil ekstrak, lanjutkan unduhan\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            # Mengunduh file dengan progress bar\n",
    "            response = requests.get(url, stream=True, timeout=10)\n",
    "            response.raise_for_status()  # Cek jika ada error HTTP\n",
    "\n",
    "            total_size = int(response.headers.get('content-length', 0))\n",
    "            with open(file_path, \"wb\") as file, tqdm(\n",
    "                    desc=f\"Downloading {filename}\",\n",
    "                    total=total_size,\n",
    "                    unit='B', unit_scale=True, unit_divisor=1024,\n",
    "            ) as bar:\n",
    "                for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                    file.write(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "\n",
    "            print(f\"\\nFile downloaded to {file_path}\")\n",
    "        else:\n",
    "            print(f\"{filename} sudah ada di {file_path}.\")\n",
    "\n",
    "        # Mengekstrak file zip jika belum ada hasil ekstrak\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "            print(f\"Files extracted to {extract_dir}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Error downloading the file: {e}\")\n",
    "\n",
    "    except zipfile.BadZipFile:\n",
    "        raise Exception(\"Error: The downloaded file is not a valid zip file.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Menghapus file zip yang sudah diekstrak jika is_file_removed=True\n",
    "        if os.path.exists(file_path) and is_file_removed:\n",
    "            os.remove(file_path)\n",
    "            print(\"Downloaded zip file removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1730797804197,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "t6Lxa-N90Hrw"
   },
   "outputs": [],
   "source": [
    "def custom_title_print(title, n_strip=80):\n",
    "    \"\"\"\n",
    "    Mencetak judul yang disesuaikan dengan garis pembatas di atas dan di bawah judul.\n",
    "\n",
    "    Args:\n",
    "        title (str): Judul yang ingin ditampilkan.\n",
    "        n_strip (int): Jumlah karakter '=' untuk membuat garis pembatas. Default adalah 80.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print('=' * n_strip)\n",
    "    print(f' {title.upper()} '.center(n_strip, '='))\n",
    "    print('=' * n_strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1730797804197,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "JeX5b6YC0HuM"
   },
   "outputs": [],
   "source": [
    "def collect_images_with_regex_and_count(path, folders, extensions_pattern):\n",
    "    \"\"\"\n",
    "    Mengumpulkan jalur gambar dari beberapa folder yang ada dalam path utama dengan memfilter gambar\n",
    "    berdasarkan ekstensi menggunakan regex. Fungsi ini mengembalikan dictionary dengan kunci berupa\n",
    "    nama folder dan nilai berupa daftar jalur file gambar.\n",
    "\n",
    "    Args:\n",
    "        path (str): Jalur utama folder yang berisi sub-folder data gambar.\n",
    "        folders (list): Daftar nama folder yang akan di-scan untuk gambar.\n",
    "        extensions_pattern (str): Pola regex untuk mencocokkan ekstensi file gambar (contoh: r'\\.(jpg|png|jpeg)$').\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary dengan kunci berupa nama folder dan nilai berupa daftar jalur file gambar yang sesuai dengan pola.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        image_paths = {folder: [] for folder in folders}   # Membuat dictionary kosong untuk menyimpan jalur gambar\n",
    "        pattern = re.compile(extensions_pattern, re.IGNORECASE) # Membuat pola regex untuk mencocokkan ekstensi gambar dengan ignore case\n",
    "\n",
    "        for folder in folders:\n",
    "            folder_path = Path(path) / folder # Mendapatkan jalur folder\n",
    "\n",
    "            for file_path in tqdm(folder_path.rglob(\"*\"), desc=f\"Collecting from {folder}\", unit=\" paths\"):\n",
    "                if pattern.search(file_path.suffix):  # Memeriksa apakah ekstensi file cocok dengan pola\n",
    "                    image_paths[folder].append(file_path)  # Menambahkan jalur file ke dalam daftar jika cocok\n",
    "\n",
    "        return image_paths  # Mengembalikan dictionary jalur gambar\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"No classes are retrieved from directory validation\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1730797804198,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "HAY6jzpP0HpG"
   },
   "outputs": [],
   "source": [
    "def get_random_images(image_paths, num_samples, seed=42):\n",
    "    \"\"\"\n",
    "    Mengambil sejumlah gambar secara acak dari daftar jalur gambar.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): Daftar jalur gambar.\n",
    "        num_samples (int): Jumlah gambar yang ingin diambil. Jika None, semua gambar akan dipilih.\n",
    "        seed (int): Seed untuk mengontrol hasil pengambilan acak agar hasilnya bisa direproduksi. Default adalah 42.\n",
    "\n",
    "    Returns:\n",
    "        list: Daftar jalur gambar yang dipilih secara acak.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    return random.sample(image_paths, min(len(image_paths) if num_samples is None else num_samples, len(image_paths)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1730797804198,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "MDjmmDH80Hk4"
   },
   "outputs": [],
   "source": [
    "def collect_and_combine_images(classes, train_path=None, valid_path=None, pattern_regex=r\"\\.(jpe?g)$\", num_images_per_class=None, seed=42):\n",
    "    \"\"\"\n",
    "    Mengumpulkan dan menggabungkan gambar dari folder training dan validation, lalu mengambil sejumlah gambar secara acak dari setiap kelas.\n",
    "\n",
    "    Args:\n",
    "        classes (list): Daftar kelas (nama folder) yang ingin diproses.\n",
    "        train_path (str): Jalur utama folder training yang berisi sub-folder data gambar.\n",
    "        valid_path (str): Jalur utama folder validation yang berisi sub-folder data gambar.\n",
    "        pattern_regex (str): Pola regex untuk mencocokkan ekstensi file gambar (contoh: r'\\.(jpg|png|jpeg)$').\n",
    "        num_images_per_class (dict): Dictionary berisi jumlah gambar yang ingin diambil untuk setiap kelas. Jika None, semua gambar akan diambil.\n",
    "        seed (int): Seed untuk pengambilan gambar secara acak. Default adalah 42.\n",
    "\n",
    "    Returns:\n",
    "        list: Daftar gabungan jalur gambar dari folder training dan validation yang diambil secara acak.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        def process_class(cls):\n",
    "            # Menggabungkan gambar dari training dan validation untuk setiap kelas\n",
    "            all_train_images = train_images_paths.get(cls, [])\n",
    "            all_valid_images = valid_images_paths.get(cls, [])\n",
    "            all_combined_images = all_train_images + all_valid_images\n",
    "\n",
    "            # Mengambil sejumlah gambar acak dari gambar gabungan\n",
    "            return get_random_images(\n",
    "                image_paths=all_combined_images,\n",
    "                num_samples=None if num_images_per_class is None else num_images_per_class.get(cls, len(all_combined_images)),\n",
    "                seed=seed\n",
    "            )\n",
    "\n",
    "        # Mencetak judul untuk proses pengumpulan gambar dari data training\n",
    "        custom_title_print(f\"COLLECT {classes} FROM TRAINING DATA\")\n",
    "        train_images_paths = collect_images_with_regex_and_count(train_path, classes, pattern_regex)\n",
    "        print()\n",
    "\n",
    "        # Mencetak judul untuk proses pengumpulan gambar dari data validation\n",
    "        custom_title_print(f\"COLLECT {classes} FROM VALIDATION DATA\")\n",
    "        valid_images_paths = collect_images_with_regex_and_count(valid_path, classes, pattern_regex)\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "        # Mencetak judul untuk proses penggabungan gambar dari training dan validation\n",
    "        custom_title_print(f\"COMBINING {classes} FROM TRAINING AND VALIDATION DATA\")\n",
    "\n",
    "        random_images = {}\n",
    "\n",
    "        # Menggunakan ThreadPoolExecutor untuk mempercepat proses pengambilan gambar dari setiap kelas secara paralel\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            results = executor.map(process_class, classes)\n",
    "\n",
    "        # Menyimpan hasil gambar acak untuk setiap kelas ke dalam dictionary\n",
    "        for cls, images in zip(classes, results):\n",
    "            random_images[cls] = images\n",
    "            print(f\"Total {cls} taken: {len(random_images[cls])}\")\n",
    "\n",
    "        # Menggabungkan semua jalur gambar dari semua kelas\n",
    "        all_images_paths = sum(random_images.values(), [])\n",
    "        all_images_paths = [str(path) for path in all_images_paths]\n",
    "        print(f\"Total images taken: {len(all_images_paths)}\".upper())\n",
    "\n",
    "        return all_images_paths\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1730797804199,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "f0NTEV7j0Hie"
   },
   "outputs": [],
   "source": [
    "def save_object(file_path, obj):\n",
    "    \"\"\"\n",
    "    Menyimpan objek ke dalam file menggunakan serialisasi dengan dill.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Jalur file tempat objek akan disimpan.\n",
    "        obj (object): Objek yang akan disimpan, bisa berupa list, dictionary, atau objek Python lainnya.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(file_path): # Memeriksa apakah file sudah ada\n",
    "            print(f\"File '{file_path}' already exists. Skipping saving.\")\n",
    "            return # Jika sudah ada, tidak perlu menyimpan lagi\n",
    "\n",
    "        dir_path = os.path.dirname(file_path)  # Mendapatkan jalur direktori dari file\n",
    "        os.makedirs(dir_path, exist_ok=True) # Membuat direktori jika belum ada\n",
    "\n",
    "        with open(file_path, 'wb') as file_obj: # Membuka file dalam mode write-binary\n",
    "            dill.dump(obj, file_obj) # Menyimpan objek menggunakan dill\n",
    "        print(f\"Object saved to {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving object: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGNgQAC_2WIf"
   },
   "source": [
    "## main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1730797804199,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "NfRkyrFJ0Hfx"
   },
   "outputs": [],
   "source": [
    "# ==========================================================================================\n",
    "# ==================================== PARENT PATH CONSTANT ================================\n",
    "# ==========================================================================================\n",
    "PARENT_DATASET_PATH = \"..\"\n",
    "DATA_URL = \"https://huggingface.co/datasets/garythung/trashnet/resolve/main/dataset-resized.zip\"\n",
    "DATA_PATH = os.path.join(PARENT_DATASET_PATH, \"artifacts\", \"data\")\n",
    "DATA_SOURCE_PATH = os.path.join(DATA_PATH, \"data_sources\")\n",
    "OBJECT_PATH = os.path.join(PARENT_DATASET_PATH, \"artifacts\", \"objects\")\n",
    "REPORT_PATH = os.path.join(PARENT_DATASET_PATH, \"artifacts\", \"reports\")\n",
    "\n",
    "# ==========================================================================================\n",
    "# ==================================== DATA PATH CONSTANT ==================================\n",
    "# ==========================================================================================\n",
    "TRAIN_PATH = os.path.join(DATA_SOURCE_PATH, \"dataset-resized\")\n",
    "TRAIN_TFRECOARD_PATH = os.path.join(DATA_PATH, \"tfrecords\", \"train_trashnet.tfrecord\")\n",
    "VALID_TFRECORD_PATH = os.path.join(DATA_PATH, \"tfrecords\", \"valid_trashnet.tfrecord\")\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================================================================\n",
    "# =============================== OBJECT PATH CONSTANT =====================================\n",
    "# ==========================================================================================\n",
    "LABEL_LIST_PATH = os.path.join(OBJECT_PATH, \"label_list.pkl\")\n",
    "CLASS_WEIGHTS_PATH = os.path.join(OBJECT_PATH, \"class_weights.pkl\")\n",
    "\n",
    "\n",
    "# ==========================================================================================\n",
    "# ======================================== CONSTANT ========================================\n",
    "# ==========================================================================================\n",
    "PATTERN_IMAGE_EXT_REGEX = r\"\\.(jpe?g|png)$\"\n",
    "LABEL_LIST = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "SPLIT_RATIO = (0.9, 0.1)\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract_zip(\n",
    "    url=DATA_URL, \n",
    "    save_dir=DATA_SOURCE_PATH, \n",
    "    extract_dir=DATA_SOURCE_PATH,\n",
    "    is_file_removed=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceifDRP7-TWH"
   },
   "source": [
    "#### Menyimpan dan Menggabungkan Gambar dari Folder Training dan Validation\n",
    "\n",
    "* Pada bagian ini, kita menggunakan fungsi `collect_and_combine_images` untuk mengumpulkan dan menggabungkan gambar, dari folder training dan validation berdasarkan kelas yang ada di `NUM_IMAGES_PER_CLASS`. Fungsi ini akan memilih gambar secara acak sesuai dengan jumlah yang telah ditentukan untuk setiap kelas.\n",
    "* Setelah proses pengumpulan gambar selesai, semua jalur gambar disimpan dalam variabel `ALL_IMAGES_PATHS` untuk digunakan pada proses selanjutnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1730797804200,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "Fb5AGeSw0Hdl",
    "outputId": "91a25a81-18b5-49d9-aff0-f075b77d308a"
   },
   "outputs": [],
   "source": [
    "ALL_IMAGES_PATHS = collect_and_combine_images(\n",
    "    classes = LABEL_LIST,\n",
    "    train_path  = TRAIN_PATH,\n",
    "    pattern_regex = PATTERN_IMAGE_EXT_REGEX,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-LgrDXA-XU5"
   },
   "source": [
    "#### Menyimpan Label Encoding\n",
    "\n",
    "* Selain itu, kita juga menggunakan fungsi `save_object` untuk menyimpan objek ke dalam file.\n",
    "* Pada contoh ini, kita menyimpan daftar kelas yang digunakan untuk encoding label di path yang telah didefinisikan sebelumnya, yaitu `LABEL_LIST_PATH`.\n",
    "* Objek ini disimpan dalam format serial menggunakan `dill` agar dapat dimuat kembali di lain waktu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1730797804585,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "EC2sAdIL0kw1",
    "outputId": "c9351aa8-4dd1-4543-9f3b-ddfce0283606"
   },
   "outputs": [],
   "source": [
    "save_object(\n",
    "    file_path=LABEL_LIST_PATH,\n",
    "    obj=LABEL_LIST\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pianmAd3-v_X"
   },
   "source": [
    "# PREPARING DATA WORKFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPYwegKg-0Jg"
   },
   "source": [
    "## Step 1. Eksplorasi Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf-8a10o-4B4"
   },
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1730797804585,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "1el7jSLv0kn-"
   },
   "outputs": [],
   "source": [
    "class FilePathInfo:\n",
    "    \"\"\"\n",
    "    Kelas FilePathInfo digunakan untuk menampilkan informasi detail tentang jalur file pada dataset, termasuk\n",
    "    nama file, ekstensi, ukuran file, dan label (jika ada). Kelas ini juga mendukung penggunaan unit ukuran\n",
    "    file yang berbeda seperti 'bytes', 'kb', 'mb', dan 'gb'.\n",
    "\n",
    "    Args:\n",
    "        unit_file_size (str, optional): Unit untuk menampilkan ukuran file ('bytes', 'kb', 'mb', 'gb'). Default adalah 'bytes'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, unit_file_size='bytes'):\n",
    "        \"\"\"\n",
    "        Inisialisasi kelas FilePathInfo dengan unit ukuran file yang diberikan.\n",
    "\n",
    "        Args:\n",
    "            unit_file_size (str, optional): Unit untuk menampilkan ukuran file ('bytes', 'kb', 'mb', 'gb'). Default adalah 'bytes'.\n",
    "        \"\"\"\n",
    "        self.unit_file_size = unit_file_size.lower()\n",
    "        self.units = ['bytes', 'kb', 'mb', 'gb']\n",
    "        if self.unit_file_size not in self.units:\n",
    "            raise ValueError(f\"Invalid unit. Choose from {self.units}.\")\n",
    "\n",
    "    def show_train_files_path_info(self, files_path_data, is_labeled=True, is_random=False):\n",
    "        \"\"\"\n",
    "        Menampilkan informasi detail tentang jalur file pada dataset training.\n",
    "\n",
    "        Args:\n",
    "            files_path_data (tf.data.Dataset): Dataset yang berisi jalur file.\n",
    "            is_labeled (bool, optional): Menunjukkan apakah dataset memiliki label. Default adalah True.\n",
    "            is_random (bool, optional): Menunjukkan apakah dataset perlu diacak sebelum ditampilkan. Default adalah False.\n",
    "\n",
    "        Returns:\n",
    "            int: Indeks label pada jalur file, jika dataset memiliki label.\n",
    "        \"\"\"\n",
    "        files_path_data_plot = self._get_files_path_data_plot(files_path_data, is_random)\n",
    "        label_index = self._display_path_info(files_path_data_plot, is_labeled)\n",
    "        return label_index\n",
    "\n",
    "    def show_test_files_path_info(self, files_path_data, is_labeled=False, is_random=False):\n",
    "        \"\"\"\n",
    "        Menampilkan informasi detail tentang jalur file pada dataset testing.\n",
    "\n",
    "        Args:\n",
    "            files_path_data (tf.data.Dataset): Dataset yang berisi jalur file.\n",
    "            is_random (bool, optional): Menunjukkan apakah dataset perlu diacak sebelum ditampilkan. Default adalah False.\n",
    "        \"\"\"\n",
    "        files_path_data_plot = self._get_files_path_data_plot(files_path_data, is_random)\n",
    "        self._display_path_info(files_path_data_plot, is_labeled)\n",
    "\n",
    "    def _get_files_path_data_plot(self, files_path_data, is_random):\n",
    "        \"\"\"\n",
    "        Mengambil subset dari dataset jalur file, dengan opsi pengacakan.\n",
    "\n",
    "        Args:\n",
    "            files_path_data (tf.data.Dataset): Dataset yang berisi jalur file.\n",
    "            is_random (bool): Apakah dataset perlu diacak.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: Subset dari dataset yang dipilih.\n",
    "        \"\"\"\n",
    "        if is_random:\n",
    "            return files_path_data.shuffle(buffer_size=files_path_data.cardinality().numpy()).take(1)\n",
    "        else:\n",
    "            return files_path_data.take(1)\n",
    "\n",
    "    def _display_path_info(self, files_path_data_plot, is_labeled):\n",
    "        \"\"\"\n",
    "        Menampilkan informasi lengkap dari jalur file yang dipilih, termasuk nama file, ekstensi, ukuran, dan label jika ada.\n",
    "\n",
    "        Args:\n",
    "            files_path_data_plot (tf.data.Dataset): Subset dari dataset yang akan ditampilkan.\n",
    "            is_labeled (bool): Menunjukkan apakah dataset memiliki label.\n",
    "\n",
    "        Returns:\n",
    "            int: Indeks label pada jalur file jika dataset berlabel.\n",
    "        \"\"\"\n",
    "        for file_path in files_path_data_plot:\n",
    "            custom_title_print(' PATH INFO ')\n",
    "            print(f'File Path: {file_path.numpy().decode(\"utf-8\")}')\n",
    "            print()\n",
    "\n",
    "            split_file_path = self._split_file_path(file_path)\n",
    "            self._display_split_file_path(split_file_path)\n",
    "\n",
    "            if is_labeled:\n",
    "                kind_data = split_file_path[-3].numpy().decode('utf-8')\n",
    "                index_label = self._display_kind_data_info(split_file_path, kind_data)\n",
    "                self._display_file_info(split_file_path, file_path)\n",
    "                return index_label\n",
    "            else:\n",
    "                self._display_file_info(split_file_path, file_path)\n",
    "\n",
    "    def _split_file_path(self, file_path):\n",
    "        \"\"\"\n",
    "        Memecah jalur file menjadi bagian-bagian menggunakan separator file system.\n",
    "\n",
    "        Args:\n",
    "            file_path (tf.Tensor): Jalur file.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Jalur file yang sudah dipecah.\n",
    "        \"\"\"\n",
    "        return tf.strings.split(file_path, os.path.sep)\n",
    "\n",
    "    def _display_split_file_path(self, split_file_path):\n",
    "        \"\"\"\n",
    "        Menampilkan jalur file yang sudah dipecah dan indeks dari setiap bagian.\n",
    "\n",
    "        Args:\n",
    "            split_file_path (tf.Tensor): Jalur file yang sudah dipecah.\n",
    "        \"\"\"\n",
    "        custom_title_print(' SPLIT FILE PATH ')\n",
    "        print(f'Split File Path: {split_file_path}')\n",
    "        print()\n",
    "\n",
    "        custom_title_print(' INDEXED PATH ')\n",
    "        result = {value: f'Index -> {index}' for index, value in enumerate(split_file_path.numpy())}\n",
    "        for key, value in result.items():\n",
    "            print(f'{value}: {key}')\n",
    "        print()\n",
    "\n",
    "    def _display_kind_data_info(self, split_file_path, kind_data):\n",
    "        \"\"\"\n",
    "        Menampilkan indeks dan label dari data berdasarkan jenisnya.\n",
    "\n",
    "        Args:\n",
    "            split_file_path (tf.Tensor): Jalur file yang sudah dipecah.\n",
    "            kind_data (str): Jenis data yang ada di jalur file.\n",
    "\n",
    "        Returns:\n",
    "            int: Indeks label pada jalur file.\n",
    "        \"\"\"\n",
    "        custom_title_print(f' KIND DATA INDEX {kind_data} ')\n",
    "        index = tf.where(tf.equal(split_file_path, kind_data))[0][0]\n",
    "        print(f'Index of \"{kind_data}\": {index}')\n",
    "        print()\n",
    "\n",
    "        index_label = index + 1\n",
    "        custom_title_print(' INDEX LABEL ')\n",
    "        print(f'Index Label: {index_label}')\n",
    "        print()\n",
    "\n",
    "        custom_title_print(' LABEL ')\n",
    "        print(f'Label: {split_file_path[index_label]}')\n",
    "        print()\n",
    "\n",
    "        return index_label.numpy()\n",
    "\n",
    "    def _display_file_info(self, split_file_path, file_path):\n",
    "        \"\"\"\n",
    "        Menampilkan informasi detail tentang file seperti nama, ekstensi, dan ukuran file.\n",
    "\n",
    "        Args:\n",
    "            split_file_path (tf.Tensor): Jalur file yang sudah dipecah.\n",
    "            file_path (tf.Tensor): Jalur file.\n",
    "        \"\"\"\n",
    "        file_name = split_file_path[-1].numpy().decode('utf-8')\n",
    "        custom_title_print(' FILE NAME ')\n",
    "        print(f'File Name: {file_name}')\n",
    "        print()\n",
    "\n",
    "        file_extension = os.path.splitext(file_name)[1]\n",
    "        custom_title_print(' FILE EXTENSION ')\n",
    "        print(f'File Extension: {file_extension}')\n",
    "        print()\n",
    "\n",
    "        image_size = Image.open(file_path.numpy().decode('utf-8')).size\n",
    "        custom_title_print(' IMAGE SIZE (PX)')\n",
    "        print(f'Image Size: \\n width={image_size[0]} \\n height={image_size[1]}')\n",
    "        print()\n",
    "\n",
    "        file_size = os.path.getsize(file_path.numpy().decode('utf-8'))\n",
    "        file_size = self._format_file_size(file_size)\n",
    "        custom_title_print(' FILE SIZE ')\n",
    "        print(f'File Size: {file_size} {self.unit_file_size}')\n",
    "        print()\n",
    "\n",
    "\n",
    "    def _format_file_size(self, size):\n",
    "        \"\"\"\n",
    "        Memformat ukuran file sesuai dengan unit yang dipilih.\n",
    "\n",
    "        Args:\n",
    "            size (int): Ukuran file dalam bytes.\n",
    "\n",
    "        Returns:\n",
    "            str: Ukuran file yang sudah diformat.\n",
    "        \"\"\"\n",
    "        if self.unit_file_size == 'kb':\n",
    "            size /= 1024\n",
    "        elif self.unit_file_size == 'mb':\n",
    "            size /= 1024 ** 2\n",
    "        elif self.unit_file_size == 'gb':\n",
    "            size /= 1024 ** 3\n",
    "\n",
    "        return f'{size:.4f}' if self.unit_file_size != 'bytes' else size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1730797804586,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "whvntC_ZA108"
   },
   "outputs": [],
   "source": [
    "def images_to_sprite(image_paths, sprite_size=(256, 256), background_color=(255, 255, 255)):\n",
    "    \"\"\"\n",
    "    Membuat sprite image dari sekumpulan gambar dengan menyusunnya dalam grid.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): Daftar path gambar yang akan digabungkan.\n",
    "        sprite_size (tuple): Ukuran akhir (width, height) dari tiap gambar dalam sprite.\n",
    "        background_color (tuple): Warna latar belakang (R, G, B) untuk area kosong di grid.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: Gambar sprite hasil penggabungan.\n",
    "    \"\"\"\n",
    "\n",
    "    # Hitung jumlah gambar dan tentukan ukuran grid untuk menampung semua gambar\n",
    "    num_images = len(image_paths)\n",
    "    grid_size = math.ceil(math.sqrt(num_images))  # Tentukan ukuran grid sebagai square root dari jumlah gambar\n",
    "\n",
    "    # Buat kanvas kosong dengan background color\n",
    "    sprite_width = grid_size * sprite_size[0]\n",
    "    sprite_height = grid_size * sprite_size[1]\n",
    "    sprite_image = Image.new(\"RGB\", (sprite_width, sprite_height), background_color)\n",
    "\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        # Buka dan resize setiap gambar\n",
    "        img = Image.open(image_path)\n",
    "        img = img.resize(sprite_size, Image.LANCZOS)\n",
    "\n",
    "        # Tentukan posisi gambar dalam grid\n",
    "        row = idx // grid_size\n",
    "        col = idx % grid_size\n",
    "        sprite_image.paste(img, (col * sprite_size[0], row * sprite_size[1]))\n",
    "\n",
    "    return sprite_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbROzz1C--1x"
   },
   "source": [
    "### main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1730797804586,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "6DFIvhcz-99h",
    "outputId": "136117d2-0b40-4c62-969c-831b205917a2"
   },
   "outputs": [],
   "source": [
    "# Ekstrak nama kategori dari path\n",
    "categories = [os.path.basename(os.path.dirname(path)) for path in ALL_IMAGES_PATHS]\n",
    "\n",
    "# Hitung jumlah tiap kategori\n",
    "category_counts = Counter(categories)\n",
    "\n",
    "# Plot distribusi kategori sebagai bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(category_counts.keys(), category_counts.values(), color='skyblue')\n",
    "plt.title('Distribusi Kategori Gambar')\n",
    "plt.xlabel('Kategori')\n",
    "plt.ylabel('Jumlah Gambar')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5djnwxm-DHqX"
   },
   "source": [
    "Dari grafik, bisa kita lihat beberapa hal penting terkait distribusi data di dataset **trashnet** ini:\n",
    "\n",
    "1. **Ketidakseimbangan Kelas**  \n",
    "   Dataset ini terlihat **imbalance** karena beberapa kelas punya jumlah sampel yang jauh lebih banyak dibanding kelas lain. Misalnya:\n",
    "   - **\"Paper\"** memiliki jumlah sampel terbanyak, menunjukkan bahwa kelas ini mendominasi dataset.\n",
    "   - **\"Trash\"** adalah kelas minoritas dengan jumlah sampel yang paling sedikit, membuatnya jauh di bawah kelas lain.\n",
    "\n",
    "2. **Potensi Bias Model**  \n",
    "   Ketidakseimbangan data ini berpotensi menyebabkan bias pada model saat training. Jika model dilatih pada dataset seperti ini tanpa penyesuaian, kemungkinan besar model akan lebih **cenderung mengenali kelas mayoritas** (seperti \"paper\") dengan akurasi lebih tinggi. Di sisi lain, model mungkin **sulit mengenali kelas dengan data sedikit** (seperti \"trash\"), dan ini bisa berujung pada kinerja yang buruk pada kelas tersebut.\n",
    "\n",
    "3. **Kebutuhan Augmentasi atau Penyesuaian**  \n",
    "   Mengingat perbedaan jumlah sampel antar kelas, ada baiknya kita mempertimbangkan teknik **oversampling** atau **weighted loss** saat melatih model. Misalnya:\n",
    "   - **Weighted Loss Function**: Memberikan bobot lebih besar ke kelas minoritas (misalnya \"trash\") dalam fungsi loss dapat membantu model untuk tidak \"mengabaikan\" kelas tersebut selama proses training.\n",
    "\n",
    "4. **Evaluasi dengan Metode yang Tepat**  \n",
    "   Karena dataset tidak seimbang, metrik evaluasi seperti **accuracy** mungkin tidak cukup mewakili performa model secara keseluruhan. Misalnya, model bisa saja mencapai akurasi tinggi hanya dengan mengenali kelas mayoritas dengan baik, tapi gagal di kelas minoritas. Oleh karena itu, disarankan untuk memakai **precision, recall, dan F1-score** per kelas agar lebih jelas performa model di tiap kelas.\n",
    "\n",
    "5. **Impak pada Aplikasi di Dunia Nyata**  \n",
    "   Jika dataset ini digunakan untuk aplikasi nyata (misalnya, sistem klasifikasi sampah otomatis), ketidakseimbangan ini bisa mengurangi efektivitasnya. Misalnya, jika model sering gagal mengenali \"trash,\" ini mungkin menyebabkan sampah yang sebenarnya perlu dibuang atau diolah dengan cara tertentu malah diklasifikasi salah, sehingga sistem tidak dapat bekerja optimal.\n",
    "\n",
    "Kesimpulan\n",
    "Secara keseluruhan, **grafik ini menunjukkan adanya ketidakseimbangan yang perlu diatasi** untuk memastikan model bisa mengenali semua kelas dengan baik, bukan hanya kelas mayoritas. Implementasi teknik handling imbalance seperti **augmentation pada kelas minoritas**, **weighted loss**, atau **evaluasi dengan metrik yang tepat** sangat disarankan untuk mencapai performa yang lebih adil di seluruh kelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1NX2SIlnZ2-Vb6ofuEQimZyaQi9yUpA-C"
    },
    "executionInfo": {
     "elapsed": 11600,
     "status": "ok",
     "timestamp": 1730797816172,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "Iv4iNvWRFWQ9",
    "outputId": "374acd91-6bc1-4ca4-8e28-f2506afafe4a"
   },
   "outputs": [],
   "source": [
    "# Buat sprite image\n",
    "num_imgs = 100\n",
    "random_images = random.sample(ALL_IMAGES_PATHS, num_imgs)\n",
    "sprite_image = images_to_sprite(random_images, sprite_size=(128, 128))\n",
    "sprite_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-pJb4hUEV1T"
   },
   "source": [
    "#### Mengumpulkan Jalur File dan Menampilkan Informasi File\n",
    "\n",
    "* Pada bagian ini, kita menggunakan `tf.data.Dataset.list_files` untuk membuat dataset dari jalur file yang telah kita kumpulkan dalam variabel `ALL_IMAGES_PATHS`. Dataset ini akan berisi jalur dari setiap gambar, dan kita dapat menggunakannya untuk proses lebih lanjut, seperti memuat gambar atau menampilkan informasi file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1730797816173,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "TNlOnSCREXiR"
   },
   "outputs": [],
   "source": [
    "tf_paths = tf.data.Dataset.list_files(ALL_IMAGES_PATHS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1730797816173,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "QU5iq9nDDpcg",
    "outputId": "e4da4cf6-dc36-45b6-a082-e950d9126adf"
   },
   "outputs": [],
   "source": [
    "for path in tf_paths.take(1):\n",
    "  print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1730797816173,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "EQEe-YBXEZD5",
    "outputId": "ffde1a14-1a3a-4ce4-8ed6-f0f8e9518059"
   },
   "outputs": [],
   "source": [
    "print(f'data: {tf_paths}')\n",
    "print(f'number of data: {tf_paths.cardinality()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lh08kzvSEexq"
   },
   "source": [
    "Setelah itu, kita membuat sebuah objek `FilePathInfo` dengan unit ukuran file 'KB'. Objek ini digunakan untuk menampilkan informasi detail tentang file yang ada di jalur tersebut, seperti nama file, ukuran, dan ekstensi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1730797816174,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "dZ979_GgEaRC"
   },
   "outputs": [],
   "source": [
    "file_info  = FilePathInfo(unit_file_size='KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGwFTG4ZEdAw"
   },
   "source": [
    "Fungsi `show_train_files_path_info` dari kelas `FilePathInfo` akan digunakan untuk menampilkan informasi tersebut secara acak dari dataset jalur file yang ada. Selain itu, kita juga mendapatkan indeks label dari file yang berisi label untuk kelas data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1730797816174,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "wThr7-qHEbwY",
    "outputId": "68a55528-37db-4104-d8da-ca35ef7005ab"
   },
   "outputs": [],
   "source": [
    "LABEL_INDEX = file_info.show_train_files_path_info(tf_paths, is_random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6fENM5iFzPq"
   },
   "source": [
    "## Step 2. Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFDKFDLZF1US"
   },
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1730797816175,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "VeFmvr09F2VY"
   },
   "outputs": [],
   "source": [
    "class DatasetSplitter:\n",
    "    \"\"\"\n",
    "    Kelas ini digunakan untuk membagi dataset menjadi tiga bagian: training, validation, dan testing.\n",
    "    Pembagian dilakukan berdasarkan rasio yang dapat dikonfigurasi, dan dataset dapat diacak sebelum dibagi.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inisialisasi kelas `DatasetSplitter`. Tidak ada argumen yang diterima saat inisialisasi.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def split_train_valid_test(self, dataset, split_ratio=None, shuffle=True, buffer_size=None, seed=42):\n",
    "        \"\"\"\n",
    "        Membagi dataset menjadi tiga bagian: training, validation, dan testing.\n",
    "\n",
    "        Args:\n",
    "            dataset (tf.data.Dataset): Dataset yang akan dibagi.\n",
    "            train_ratio (float, optional): Rasio data untuk training. Default adalah 0.7.\n",
    "            valid_ratio (float, optional): Rasio data untuk validation. Default adalah 0.2.\n",
    "            shuffle (bool, optional): Apakah dataset perlu diacak sebelum pembagian. Default adalah True.\n",
    "            buffer_size (int, optional): Ukuran buffer untuk pengacakan dataset. Jika None, buffer_size diambil dari ukuran dataset.\n",
    "            seed (int, optional): Seed untuk pengacakan dataset. Default adalah 42.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Tuple yang berisi tiga dataset yang sudah dibagi: (train_dataset, val_dataset, test_dataset).\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            dataset_size = len(dataset) if buffer_size is None else buffer_size\n",
    "\n",
    "            # Define individual ratios for training, validation, and test sets\n",
    "            train_ratio = split_ratio[0]\n",
    "            val_ratio = split_ratio[1]\n",
    "            test_ratio = round(max(1.0 - (train_ratio + val_ratio), 0), 4)  # Calculate remaining ratio for test set\n",
    "\n",
    "            # Verify the total ratio equals 1.0; raise an error if not\n",
    "            total_ratio = round(sum((train_ratio, val_ratio, test_ratio)), 2)\n",
    "            if total_ratio != 1.0:\n",
    "                raise ValueError(\"[ERROR] split_ratio must sum to 1.0.\\n\")\n",
    "\n",
    "            # Determine the number of images in each split based on the calculated ratios\n",
    "            train_size = int(round(dataset_size * train_ratio, 0))\n",
    "            val_size = int(round(dataset_size * val_ratio, 0))\n",
    "            test_size = int(round(dataset_size * test_ratio, 0))\n",
    "\n",
    "            # Randomly shuffle the image files if random_split is enabled\n",
    "            if shuffle:\n",
    "                dataset = dataset.shuffle(buffer_size=dataset_size, seed=seed)\n",
    "\n",
    "            # Split the files into training, validation, and test sets based on calculated sizes\n",
    "            train_dataset = dataset.take(train_size)\n",
    "            val_test_dataset = dataset.skip(train_size)\n",
    "\n",
    "            # Jika test_size == 0, hanya buat train dan validation dataset\n",
    "            if test_size == 0:\n",
    "                val_dataset = val_test_dataset.take(val_size)\n",
    "                self._display_info(\n",
    "                    dataset=dataset,\n",
    "                    train_dataset=train_dataset,\n",
    "                    valid_dataset=val_dataset,\n",
    "                    dataset_size=dataset_size,\n",
    "                    shuffle=shuffle,\n",
    "                    test_size=test_size\n",
    "                )\n",
    "\n",
    "                return train_dataset, val_dataset\n",
    "            else:\n",
    "                val_dataset = val_test_dataset.take(val_size)\n",
    "                test_dataset = val_test_dataset.skip(val_size)\n",
    "\n",
    "                self._display_info(\n",
    "                    dataset=dataset,\n",
    "                    train_dataset=train_dataset,\n",
    "                    valid_dataset=val_dataset,\n",
    "                    test_dataset=test_dataset,\n",
    "                    dataset_size=dataset_size,\n",
    "                    shuffle=shuffle,\n",
    "                    test_size=test_size\n",
    "                )\n",
    "\n",
    "                return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None, None, None\n",
    "\n",
    "    def _display_info(self, dataset=None, train_dataset=None, valid_dataset=None, test_dataset=None, dataset_size=None, shuffle=False, test_size=None):\n",
    "        \"\"\"\n",
    "        Menampilkan informasi mengenai pembagian dataset seperti ukuran, rasio, dan status shuffle.\n",
    "\n",
    "        Args:\n",
    "            dataset (tf.data.Dataset): Dataset asli yang belum dibagi.\n",
    "            train_dataset (tf.data.Dataset): Dataset bagian training.\n",
    "            valid_dataset (tf.data.Dataset): Dataset bagian validation.\n",
    "            test_dataset (tf.data.Dataset): Dataset bagian testing.\n",
    "            dataset_size (int): Ukuran total dataset.\n",
    "            shuffle (bool): Status apakah dataset diacak sebelum dibagi.\n",
    "        \"\"\"\n",
    "        train_ratio = len(train_dataset) / dataset_size\n",
    "        valid_ratio = len(valid_dataset) / dataset_size\n",
    "        test_ratio = len(test_dataset) / dataset_size if test_size > 0 else 0\n",
    "\n",
    "        print(f\"Total number of data: {dataset_size}\")\n",
    "        print(f\"Shuffle status: {shuffle}\")\n",
    "\n",
    "        custom_title_print(' Training Dataset ')\n",
    "        print(f\"Info data: {train_dataset}\")\n",
    "        print(f\"Training Split: {round(train_ratio * 100, 2)}%\")\n",
    "        print(f\"Number of data: {len(train_dataset)}\")\n",
    "        print()\n",
    "\n",
    "        custom_title_print(' Validation Dataset ')\n",
    "        print(f\"Info data: {valid_dataset}\")\n",
    "        print(f\"Validation Split: {round(valid_ratio * 100, 2)}%\")\n",
    "        print(f\"Number of data: {len(valid_dataset)}\")\n",
    "        print()\n",
    "\n",
    "        if test_size > 0:\n",
    "            custom_title_print(' Test Dataset ')\n",
    "            print(f\"Info data: {test_dataset}\")\n",
    "            print(f\"Test Split: {round(test_ratio * 100, 2)}%\")\n",
    "            print(f\"Number of data: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1730797816175,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "6Inz2_uAF4Gb"
   },
   "outputs": [],
   "source": [
    "def extract_class_from_path_tf(path_tensor):\n",
    "    \"\"\"\n",
    "    Mengekstrak nama kelas dari jalur file yang disimpan dalam bentuk tensor.\n",
    "\n",
    "    Args:\n",
    "        path_tensor (tf.Tensor): Tensor yang berisi jalur file.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Tensor yang berisi nama kelas yang diekstrak dari jalur file.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        parts = tf.strings.split(path_tensor, os.path.sep)\n",
    "        class_name = parts[-2]  # Nama kelas biasanya berada di posisi kedua dari belakang dalam jalur\n",
    "        return class_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1730797816176,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "yO9CK7TEF5w_"
   },
   "outputs": [],
   "source": [
    "def calculate_class_distribution_tf(dataset, class_labels):\n",
    "    \"\"\"\n",
    "    Menghitung distribusi kelas dan class weight menggunakan `compute_class_weight` dari sklearn.\n",
    "\n",
    "    Args:\n",
    "        dataset (tf.data.Dataset): Dataset TensorFlow berisi gambar dan label.\n",
    "        class_labels (list): Daftar nama kelas yang diurutkan (misal: ['cardboard', 'glass', ...]).\n",
    "\n",
    "    Returns:\n",
    "        tuple: class_counts (Counter), class_weights (dict)\n",
    "               class_weights dalam bentuk {label_index: weight}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Mengambil nama kelas dari path dan mengonversinya menjadi list\n",
    "        class_names = dataset.map(lambda x: extract_class_from_path_tf(x))\n",
    "        class_names_list = list(class_names.batch(1000).as_numpy_iterator())\n",
    "        all_class_names = [name.decode('utf-8') for batch in class_names_list for name in batch]\n",
    "\n",
    "        # Hitung distribusi kelas\n",
    "        class_counts = Counter(all_class_names)\n",
    "\n",
    "        # Konversi nama kelas ke indeks numerik sesuai `class_labels`\n",
    "        class_indices = [class_labels.index(name) for name in all_class_names]\n",
    "\n",
    "        # Hitung class weight menggunakan sklearn\n",
    "        class_weight_values = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(class_indices),\n",
    "            y=class_indices\n",
    "        )\n",
    "\n",
    "        # Buat dict class_weights sesuai indeks\n",
    "        class_weights = {i: weight for i, weight in enumerate(class_weight_values)}\n",
    "\n",
    "        return class_counts, class_weights\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1730797816176,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "KCGrAykoF6UI"
   },
   "outputs": [],
   "source": [
    "def print_class_distribution(distribution):\n",
    "    \"\"\"\n",
    "    Mencetak distribusi kelas ke layar.\n",
    "\n",
    "    Args:\n",
    "        distribution (collections.Counter): Objek Counter yang berisi distribusi kelas.\n",
    "    \"\"\"\n",
    "    for class_name, count in sorted(distribution.items()):\n",
    "        print(f\"{class_name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBl_3qjxF86_"
   },
   "source": [
    "### main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1730797816176,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "_BFcr3wRF7bh"
   },
   "outputs": [],
   "source": [
    "splitter = DatasetSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1730797816177,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "QLnCysIFF8ke",
    "outputId": "03db9c07-5755-4e95-9e1b-bb460d58b645"
   },
   "outputs": [],
   "source": [
    "train_tf_paths, valid_tf_paths = splitter.split_train_valid_test(\n",
    "    dataset=tf_paths,\n",
    "    split_ratio=SPLIT_RATIO,\n",
    "    shuffle=True,\n",
    "    seed=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1730797816177,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "2eFoJe1iF_yQ",
    "outputId": "9c89e722-dc03-439f-9f9b-9acdf753e4be"
   },
   "outputs": [],
   "source": [
    "for train_path, valid_path in zip(train_tf_paths.take(1), valid_tf_paths.take(1)):\n",
    "    print(train_path)\n",
    "    print(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1730797816555,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "OgtTiVzDMkVf"
   },
   "outputs": [],
   "source": [
    "train_class_distribution, class_weights = calculate_class_distribution_tf(train_tf_paths, LABEL_LIST)\n",
    "valid_class_distribution, _ = calculate_class_distribution_tf(valid_tf_paths, LABEL_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1730797816555,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "d_7ROjG3dJLr",
    "outputId": "52e08689-558a-4dc1-cb55-793ae80a8c31"
   },
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_u7gFEHeRKD"
   },
   "source": [
    "#### Menyimpan Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1730797816555,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "GgX9ARJFeKaK",
    "outputId": "083baaf9-a85d-41d6-cba8-17366e4379c6"
   },
   "outputs": [],
   "source": [
    "save_object(\n",
    "    file_path=CLASS_WEIGHTS_PATH,\n",
    "    obj=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1730797816556,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "7nopprMVMllA",
    "outputId": "c33fe8d7-9a12-419a-951c-b06a98f7d994"
   },
   "outputs": [],
   "source": [
    "custom_title_print(\"Class distribution on Train set:\")\n",
    "print_class_distribution(train_class_distribution)\n",
    "print()\n",
    "\n",
    "custom_title_print(\"Class distribution in Validation set:\")\n",
    "print_class_distribution(valid_class_distribution)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWL_5sYXNH_9"
   },
   "source": [
    "## Step 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAmpb3lXNJ44"
   },
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1730797816556,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "1NGauxdoNIWt"
   },
   "outputs": [],
   "source": [
    "def show_data_info(**datasets):\n",
    "    \"\"\"\n",
    "    Menampilkan informasi detail tentang dataset yang diberikan.\n",
    "\n",
    "    Args:\n",
    "        **datasets: Satu atau lebih dataset yang ingin ditampilkan informasi.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        for dataset_name, dataset in datasets.items():\n",
    "            custom_title_print(f\"{dataset_name} info\")\n",
    "            print(f'info {dataset_name}: {dataset}')\n",
    "            print(f'number of {dataset_name}: {len(dataset)}')\n",
    "            print()\n",
    "    except Exception as e:\n",
    "        print(f'''\n",
    "            explicitly input parameter names such as:\n",
    "            show_data_info(train_dataset=train_ds, valid_dataset=valid_ds)\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1730797816556,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "IS8zcLmPNLXs"
   },
   "outputs": [],
   "source": [
    "def create_label_list_table(label_list, default_value=-1):\n",
    "    \"\"\"\n",
    "    Membuat StaticHashTable untuk encoding label berdasarkan daftar label yang diberikan.\n",
    "\n",
    "    Args:\n",
    "    - label_list (list): Daftar label yang ingin di-encode.\n",
    "    - default_value (int): Nilai default jika label tidak ditemukan di dalam tabel.\n",
    "\n",
    "    Returns:\n",
    "    - label_table (tf.lookup.StaticHashTable): Tabel hash untuk label encoding.\n",
    "    \"\"\"\n",
    "    # Buat tensor dari daftar label (keys)\n",
    "    keys_tensor = tf.constant(label_list)\n",
    "\n",
    "    # Buat nilai integer yang berkaitan dengan setiap label (values)\n",
    "    values_tensor = tf.range(len(label_list))\n",
    "\n",
    "    # Inisialisasi Key-Value pairs untuk tabel hash\n",
    "    table_init = tf.lookup.KeyValueTensorInitializer(keys_tensor, values_tensor)\n",
    "\n",
    "    # Membuat StaticHashTable\n",
    "    label_table = tf.lookup.StaticHashTable(table_init, default_value=default_value)\n",
    "\n",
    "    return label_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1730797816556,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "Eu5joqPwNMWj"
   },
   "outputs": [],
   "source": [
    "def save_images_from_dataset(dataset, output_dir, label_mapping, max_images_per_class=None):\n",
    "    \"\"\"\n",
    "    Simpan gambar dari TensorFlow dataset ke folder berdasarkan label.\n",
    "\n",
    "    Args:\n",
    "    - dataset: TensorFlow dataset yang berisi pasangan (image, label).\n",
    "    - output_dir: Path direktori utama untuk menyimpan gambar.\n",
    "    - label_mapping: List yang memetakan indeks label ke nama kelas. Contoh: ['akiec', 'bcc'].\n",
    "    - max_images_per_class: (Optional) Jumlah maksimum gambar yang disimpan per kelas. Jika None, simpan semua gambar.\n",
    "    \"\"\"\n",
    "\n",
    "    # Buat direktori output jika belum ada\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Dictionary untuk melacak jumlah gambar yang sudah disimpan per kelas\n",
    "    saved_count_per_class = {class_name: 0 for class_name in label_mapping}\n",
    "\n",
    "    # Hitung total data jika `max_images_per_class` tidak diberikan\n",
    "    total_images = {class_name: 0 for class_name in label_mapping}\n",
    "    if max_images_per_class is None:\n",
    "        for image, label in dataset:\n",
    "            label_np = label.numpy()\n",
    "            class_name = label_mapping[label_np]\n",
    "            total_images[class_name] += 1\n",
    "\n",
    "    # Iterasi setiap batch di dataset dengan looping\n",
    "    for image, label in dataset:\n",
    "        # Convert Tensor ke NumPy array untuk gambar dan label\n",
    "        image_np = image.numpy()\n",
    "        label_np = label.numpy()\n",
    "\n",
    "        # Cari nama kelas berdasarkan label\n",
    "        class_name = label_mapping[label_np]\n",
    "\n",
    "        # Jika batas max_images_per_class tercapai untuk kelas ini, skip iterasi berikutnya\n",
    "        if max_images_per_class is not None and saved_count_per_class[class_name] >= max_images_per_class:\n",
    "            # Jika semua kelas sudah mencapai batas penyimpanan gambar, keluar dari loop utama\n",
    "            if all(count >= max_images_per_class for count in saved_count_per_class.values()):\n",
    "                print(\"Mencapai batas maksimum gambar per kelas, berhenti menyimpan.\")\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        # Buat path folder untuk setiap label (kelas)\n",
    "        class_folder = os.path.join(output_dir, class_name)\n",
    "        if not os.path.exists(class_folder):\n",
    "            os.makedirs(class_folder)  # Buat folder jika belum ada\n",
    "\n",
    "        # Tentukan path untuk menyimpan gambar dengan urutan numerik\n",
    "        saved_count_per_class[class_name] += 1\n",
    "        file_name = f\"{class_name}_{saved_count_per_class[class_name]}.jpg\"\n",
    "        file_path = os.path.join(class_folder, file_name)\n",
    "\n",
    "        # Cek jika file sudah ada, skip\n",
    "        if not os.path.exists(file_path):\n",
    "            # Konversi ke uint8 dengan mengubah range dari [0, 1] ke [0, 255]\n",
    "            image_np_uint8 = (image_np * 255).astype(np.uint8)\n",
    "\n",
    "            # Gunakan image_np_uint8 untuk menyimpan gambar dengan PIL\n",
    "            image_pil = Image.fromarray(image_np_uint8)\n",
    "            image_pil.save(file_path)\n",
    "\n",
    "            # Jika `max_images_per_class` tidak diberikan, gunakan jumlah total gambar sebagai progress\n",
    "            total_images_class = max_images_per_class if max_images_per_class is not None else total_images[class_name]\n",
    "\n",
    "            # Tampilkan progress bar khusus untuk kelas ini\n",
    "            with tqdm(total=total_images_class, desc=f\"Saving {class_name} images\", unit=\"image\", position=0, leave=False) as pbar:\n",
    "                pbar.update(1)\n",
    "\n",
    "    print(f\"Gambar yang disimpan per kelas: {saved_count_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1730797817048,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "Bl8d9BWLNN6K"
   },
   "outputs": [],
   "source": [
    "class ImagePreprocessor:\n",
    "    \"\"\"\n",
    "    Kelas ini bertanggung jawab untuk memproses gambar sebelum digunakan dalam pelatihan model.\n",
    "    Ini mencakup konversi jalur file gambar menjadi gambar, mengubah ukuran gambar, normalisasi,\n",
    "    dan augmentasi gambar untuk dataset pelatihan, validasi, dan pengujian.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label_index, label_encoding, target_size=(200, 200), is_gray=False):\n",
    "        \"\"\"\n",
    "        Inisialisasi kelas `ImagePreprocessor`.\n",
    "\n",
    "        Args:\n",
    "            label_index (int): Indeks jalur untuk mengambil label dari jalur gambar.\n",
    "            label_encoding (tf.lookup.StaticHashTable): Objek lookup untuk mendapatkan label numerik dari nama kelas.\n",
    "            target_size (tuple, optional): Ukuran target gambar yang diinginkan. Default adalah (200, 200).\n",
    "            is_gray (bool, optional): Jika True, gambar akan dikonversi menjadi grayscale. Default adalah False.\n",
    "        \"\"\"\n",
    "        self.label_index = label_index\n",
    "        self.label_encoding = label_encoding\n",
    "        self.target_size = target_size\n",
    "        self.is_gray = is_gray\n",
    "        self.channels = 1 if self.is_gray else 3\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ _CONVERT_PATH_TO_IMAGE_SINGLE --------------------------------\n",
    "    # ===================================================================================================\n",
    "\n",
    "    def _convert_path_to_image_single(self, image_path):\n",
    "        \"\"\"\n",
    "        Mengonversi jalur file gambar menjadi gambar dan label.\n",
    "\n",
    "        Args:\n",
    "            image_path (str): Jalur file gambar.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Gambar yang dikonversi, label numerik, dan jalur file gambar.\n",
    "        \"\"\"\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_image(image, channels= self.channels)\n",
    "        image.set_shape([None, None,  self.channels])\n",
    "        split_img_path = tf.strings.split(image_path, os.path.sep)\n",
    "        label = self.label_encoding.lookup(split_img_path[self.label_index])\n",
    "        return image, label, image_path\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ _RESIZE_IMAGE ------------------------------------------------\n",
    "    # ===================================================================================================\n",
    "\n",
    "    def _resize_image(self, image, label):\n",
    "        \"\"\"\n",
    "        Mengubah ukuran gambar ke ukuran target yang telah ditentukan.\n",
    "\n",
    "        Args:\n",
    "            image (tf.Tensor): Gambar input.\n",
    "            label (int): Label gambar.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Gambar yang diubah ukurannya dan label.\n",
    "        \"\"\"\n",
    "        image = tf.image.resize(image, size=(self.target_size[0], self.target_size[1]))\n",
    "        image = tf.cast(image, tf.uint8)\n",
    "        return image, label\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ _NORMALIZE_IMAGE ---------------------------------------------\n",
    "    # ===================================================================================================\n",
    "\n",
    "    def _normalize_image(self, image, label):\n",
    "        \"\"\"\n",
    "        Melakukan normalisasi gambar dengan membagi nilai pixel dengan 255.\n",
    "\n",
    "        Args:\n",
    "            image (tf.Tensor): Gambar input.\n",
    "            label (int): Label gambar.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Gambar yang dinormalisasi dan label.\n",
    "        \"\"\"\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = image / 255.0\n",
    "        label = tf.cast(label, tf.int32)\n",
    "        return image, label\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ _AUGMENT_IMAGE -----------------------------------------------\n",
    "    # ===================================================================================================\n",
    "\n",
    "    def _augment_image(self, image, label=None):\n",
    "        \"\"\"\n",
    "        Melakukan augmentasi pada gambar, termasuk flipping horizontal dan vertikal serta rotasi 90 atau -90 derajat.\n",
    "\n",
    "        Args:\n",
    "            image (tf.Tensor): Gambar input.\n",
    "            label (int, optional): Label gambar.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Gambar yang telah diaugmentasi dan label (jika ada).\n",
    "        \"\"\"\n",
    "\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        image = tf.clip_by_value(image, clip_value_min=0., clip_value_max=1.)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ _APPLY_CONVERT_PATH_TO_IMAGE ---------------------------------\n",
    "    # ===================================================================================================\n",
    "\n",
    "    def _apply_convert_path_to_image(self, dataset):\n",
    "        \"\"\"\n",
    "        Melakukan konversi jalur file ke gambar untuk dataset tertentu.\n",
    "\n",
    "        Args:\n",
    "            dataset (tf.data.Dataset): Dataset jalur file gambar.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: Dataset gambar yang dikonversi dari jalur file.\n",
    "        \"\"\"\n",
    "        return dataset.map(\n",
    "            map_func=lambda image_path: self._convert_path_to_image_single(image_path),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        ).cache()\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ _APPLY_IMAGE_RESIZING ----------------------------------------\n",
    "    # ===================================================================================================\n",
    "\n",
    "    def _apply_image_resizing(self, dataset):\n",
    "        \"\"\"\n",
    "        Mengubah ukuran gambar pada dataset tertentu.\n",
    "\n",
    "        Args:\n",
    "            dataset (tf.data.Dataset): Dataset gambar.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: Dataset gambar yang sudah diubah ukurannya.\n",
    "        \"\"\"\n",
    "        return dataset.map(\n",
    "            map_func=lambda image, label, path: self._resize_image(image, label),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ _APPLY_IMAGE_NORMALIZATION -----------------------------------\n",
    "    # ===================================================================================================\n",
    "\n",
    "    def _apply_image_normalization(self, dataset):\n",
    "        \"\"\"\n",
    "        Melakukan normalisasi gambar pada dataset tertentu.\n",
    "\n",
    "        Args:\n",
    "            dataset (tf.data.Dataset): Dataset gambar.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: Dataset gambar yang sudah dinormalisasi.\n",
    "        \"\"\"\n",
    "        return dataset.map(\n",
    "            map_func=lambda image, label: self._normalize_image(image, label),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ _APPLY_IMAGE_AUGMENTATION ------------------------------------\n",
    "    # ===================================================================================================\n",
    "\n",
    "    def _apply_image_augmentation(self, dataset):\n",
    "        \"\"\"\n",
    "        Melakukan augmentasi gambar pada dataset tertentu.\n",
    "\n",
    "        Args:\n",
    "            dataset (tf.data.Dataset): Dataset gambar.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: Dataset gambar yang sudah diaugmentasi.\n",
    "        \"\"\"\n",
    "        return dataset.map(\n",
    "            map_func=lambda image, label: self._augment_image(image, label),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ CONVERT_PATH_TO_IMAGE ----------------------------------------\n",
    "    # ===================================================================================================\n",
    "    def convert_path_to_image(self, **datasets):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return (self._apply_convert_path_to_image(dataset) for dataset in datasets.values())\n",
    "\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ----------------------------------------- IMAGE_RESIZING ------------------------------------------\n",
    "    # ===================================================================================================\n",
    "    def image_resizing(self, **datasets):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return (self._apply_image_resizing(dataset) for dataset in datasets.values())\n",
    "\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ IMAGE_NORMALIZATION ------------------------------------------\n",
    "    # ===================================================================================================\n",
    "    def image_normalization(self, **datasets):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return (self._apply_image_normalization(dataset) for dataset in datasets.values())\n",
    "\n",
    "    # ===================================================================================================\n",
    "    # ------------------------------------ IMAGE_AUGMENTATION--------------------------------------------\n",
    "    # ===================================================================================================\n",
    "    def image_augmentation(self, **datasets):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return (self._apply_image_augmentation(dataset) for dataset in datasets.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1730797817048,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "5NmR_0CuNPiI"
   },
   "outputs": [],
   "source": [
    "class DataInspector:\n",
    "    \"\"\"\n",
    "    Kelas `DataInspector` bertanggung jawab untuk melakukan inspeksi dan visualisasi\n",
    "    gambar dalam dataset pelatihan, validasi, dan pengujian.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label_encoding, figsize):\n",
    "        \"\"\"\n",
    "        Inisialisasi kelas `DataInspector`.\n",
    "\n",
    "        Args:\n",
    "            label_encoding (dict): Mapping dari label numerik ke label kelas.\n",
    "            figsize (tuple): Ukuran figure untuk plot visualisasi gambar.\n",
    "        \"\"\"\n",
    "        self.label_encoding = label_encoding\n",
    "        self.figsize = figsize\n",
    "\n",
    "    def _custom_title_print(self, title, n_strip=80):\n",
    "        \"\"\"\n",
    "        Menampilkan judul yang diformat khusus dengan tanda pemisah.\n",
    "\n",
    "        Args:\n",
    "            title (str): Judul yang akan ditampilkan.\n",
    "            n_strip (int, optional): Jumlah karakter untuk garis pemisah. Default adalah 80.\n",
    "        \"\"\"\n",
    "        print('=' * n_strip)\n",
    "        print(f' {title.upper()} '.center(n_strip, '='))\n",
    "        print('=' * n_strip)\n",
    "\n",
    "    def _inspect_single_dataset(self, dataset, ds_name, ispath, idx):\n",
    "        \"\"\"\n",
    "        Helper function untuk menginspeksi dataset tertentu.\n",
    "\n",
    "        Args:\n",
    "            dataset (tf.data.Dataset): Dataset yang akan diinspeksi.\n",
    "            ds_name (str): Nama dataset (train, valid, test).\n",
    "            idx (int, optional): Indeks untuk memulai pengambilan contoh gambar. Default 1.\n",
    "        \"\"\"\n",
    "\n",
    "        plt.figure(figsize=self.figsize)\n",
    "\n",
    "        if ispath:\n",
    "            for i, (image, label, path) in enumerate(dataset.skip(idx).take(1), 1):\n",
    "                self._print_data_info(f\"{ds_name}_data info\", image, label, path)\n",
    "                self._plot_images(ds_name, image, label)\n",
    "        else:\n",
    "            for i, (image, label) in enumerate(dataset.skip(idx).take(1), 1):\n",
    "                self._print_data_info(f\"{ds_name}_data info\", image, label)\n",
    "                self._plot_images(ds_name, image, label)\n",
    "        plt.show()\n",
    "\n",
    "    def _print_data_info(self, title, image, label, image_path=None):\n",
    "        \"\"\"\n",
    "        Menampilkan informasi mendetail tentang gambar dan label.\n",
    "\n",
    "        Args:\n",
    "            title (str): Judul informasi yang akan ditampilkan.\n",
    "            image (tf.Tensor): Gambar yang diinspeksi.\n",
    "            label (int): Label gambar yang diinspeksi.\n",
    "            image_path (str, optional): Jalur file gambar (jika ada). Default adalah None.\n",
    "        \"\"\"\n",
    "        print('\\n\\n')\n",
    "        self._custom_title_print(title)\n",
    "\n",
    "        if image_path is not None:\n",
    "            print(f'image path: {image_path}')\n",
    "\n",
    "        print(f'shape-image: {image.shape}')\n",
    "        print(f'dtype-image: {image.dtype}')\n",
    "        print(f'max-intensity: {tf.reduce_max(image)}')\n",
    "        print(f'min-intensity: {tf.reduce_min(image)}')\n",
    "\n",
    "        print(f'label: {label} -> {self.label_encoding[label.numpy()]}')\n",
    "        print(f'label-shape: {label.shape}')\n",
    "        print(f'label-type: {label.dtype}')\n",
    "        print()\n",
    "\n",
    "    def _plot_images(self, ds_name, image, label):\n",
    "        \"\"\"\n",
    "        Memvisualisasikan gambar dari dataset pelatihan, validasi, dan pengujian secara dinamis.\n",
    "\n",
    "        Args:\n",
    "            datasets (dict): Dataset yang ingin di-plot (train_image, valid_image, test_image).\n",
    "        \"\"\"\n",
    "        plt.title(f'{ds_name.capitalize()} Label: {self.label_encoding[label.numpy()]}')\n",
    "        plt.imshow(image.numpy(), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    def inspect(self, ispath=False, idx=1, **datasets):\n",
    "        \"\"\"\n",
    "        Menginspeksi gambar dari dataset pelatihan, validasi, atau pengujian (atau gabungan).\n",
    "\n",
    "        Args:\n",
    "            datasets (dict): Dataset yang ingin diinspeksi (train_ds, valid_ds, test_ds).\n",
    "                             Bisa masukkan satu atau lebih.\n",
    "        \"\"\"\n",
    "        # Looping dinamis sesuai dataset yang diberikan (train, valid, test)\n",
    "        for ds_name, ds in datasets.items():\n",
    "            self._inspect_single_dataset(ds, ds_name, ispath, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nkc7ie_N3lR"
   },
   "source": [
    "### main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1730797817049,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "eT99haw_NQ9n",
    "outputId": "0300bd82-8dd0-456c-e515-49a47fce16ff"
   },
   "outputs": [],
   "source": [
    "print(LABEL_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730797817049,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "4ClyEzriN6nJ",
    "outputId": "3c322b3b-3a2d-4722-90d0-3f81ec7e5679"
   },
   "outputs": [],
   "source": [
    "LABEL_TABLE = create_label_list_table(LABEL_LIST, default_value=-1)\n",
    "LABEL_TABLE.lookup(tf.constant('paper'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCYQ2foiN_dL"
   },
   "source": [
    "#### Inisialisasi objek `ImagePreprocessor` dan `DataInspector`\n",
    "\n",
    "1. `ImagePreprocessor`: Objek ini digunakan untuk melakukan preprocessing pada dataset, termasuk mengkonversi path gambar menjadi image, meresize image, normalisasi, dan augmentasi.\n",
    "  - `label_index`: Indeks label dalam path file yang digunakan untuk mencari label pada gambar.\n",
    "  - `label_list`: Lookup table yang digunakan untuk menerjemahkan label dari bentuk numerik ke label kelas.\n",
    "  - `target_size`: Ukuran target gambar (width, height) setelah resize.\n",
    "\n",
    "2. `DataInspector`: Digunakan untuk melakukan inspeksi dataset dan menampilkan gambar beserta informasinya.\n",
    "  - `LABEL_LIST`: Lookup table yang digunakan oleh `DataInspector` untuk menerjemahkan label numerik menjadi label kelas.\n",
    "  - `figsize`: Ukuran untuk visualisasi gambar dalam format subplot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730797817049,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "AXaZBGTkN7MO"
   },
   "outputs": [],
   "source": [
    "preprocessor = ImagePreprocessor(\n",
    "    label_index=LABEL_INDEX,\n",
    "    label_encoding=LABEL_TABLE,\n",
    "    target_size=IMAGE_SIZE\n",
    ")\n",
    "\n",
    "inspector = DataInspector(\n",
    "    LABEL_LIST,\n",
    "    figsize=(12,6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2AozMlYOF6-"
   },
   "source": [
    "#### Mengkonversi path gambar ke dalam format image menggunakan objek `ImagePreprocessor`\n",
    "\n",
    "Fungsi `convert_path_to_image` digunakan untuk mengubah path gambar dari dataset pelatihan, validasi, dan pengujian ke dalam bentuk image dan label yang dapat digunakan oleh TensorFlow.\n",
    "\n",
    "Output dari fungsi ini adalah dataset yang sudah dalam format (image, label, path).\n",
    "- `train_tf_paths`, `valid_tf_paths`, dan `test_tf_paths` merupakan dataset yang berisi path gambar dari dataset pelatihan, validasi, dan pengujian.\n",
    "- Fungsi `convert_path_to_image` akan memproses masing-masing dataset ini dan mengembalikan gambar yang siap untuk dilatih, divalidasi, atau diuji.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1730797817474,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "5qQev9DPOEhj"
   },
   "outputs": [],
   "source": [
    "train_tf_images, valid_tf_images = preprocessor.convert_path_to_image(\n",
    "    train_data=train_tf_paths,\n",
    "    valid_data=valid_tf_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1730797817474,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "QlC6RSIrOHqK",
    "outputId": "84841154-59eb-4f0c-dda7-867129520f5b"
   },
   "outputs": [],
   "source": [
    "show_data_info(\n",
    "    train_dataset=train_tf_images,\n",
    "    valid_dataset=valid_tf_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2339,
     "status": "ok",
     "timestamp": 1730797819807,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "HTsPBKz9OIp3",
    "outputId": "d2999935-a502-45b0-fa95-4f165999f4e4"
   },
   "outputs": [],
   "source": [
    "# Inspeksi data pada index tertentu\n",
    "inspector.inspect(\n",
    "    ispath=True,\n",
    "    idx=1,\n",
    "    train_dataset=train_tf_images,\n",
    "    valid_dataset=valid_tf_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0qp5luaOUr2"
   },
   "source": [
    "##### Cek apakah hasil gambar di atas dengan label sudah sesuai berdasarkan path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1730797819808,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "B6c1i9InOKCA",
    "outputId": "9a55b059-e9c8-427e-b185-06d5985030e7"
   },
   "outputs": [],
   "source": [
    "train_image = Image.open(f'{TRAIN_PATH}/paper/paper210.jpg')\n",
    "valid_image = Image.open(f'{TRAIN_PATH}/cardboard/cardboard132.jpg')\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(train_image)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(valid_image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_j8RsMwOfd_"
   },
   "source": [
    "#### Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1730797819808,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "52hYpXK8OWY1"
   },
   "outputs": [],
   "source": [
    "train_tf_images_resized, valid_tf_images_resized = preprocessor.image_resizing(\n",
    "    train_data=train_tf_images,\n",
    "    valid_data=valid_tf_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1730797819808,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "4QIwNVtgOo-k",
    "outputId": "e5923315-a0d5-49aa-fb09-24122dff64b0"
   },
   "outputs": [],
   "source": [
    "show_data_info(\n",
    "    train_dataset=train_tf_images_resized,\n",
    "    valid_dataset=valid_tf_images_resized\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 971,
     "status": "ok",
     "timestamp": 1730797820771,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "FtP-8RIwOqPk",
    "outputId": "8c6b5275-c8d7-4a8e-a288-ab2be4bfbb7b"
   },
   "outputs": [],
   "source": [
    "# Inspeksi data pada index tertentu\n",
    "inspector.inspect(\n",
    "    train_dataset=train_tf_images_resized,\n",
    "    valid_dataset=valid_tf_images_resized\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH7fIxZYOwhB"
   },
   "source": [
    "#### Image Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1730797821162,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "gfwP3_JcOrdr"
   },
   "outputs": [],
   "source": [
    "train_tf_images_normalized, valid_tf_images_normalized = preprocessor.image_normalization(\n",
    "    train_data=train_tf_images_resized,\n",
    "    valid_data=valid_tf_images_resized,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1730797821163,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "MCRu1UrDOyLn",
    "outputId": "ad0e5e24-f371-4d6f-ee39-cf1fa11c03d4"
   },
   "outputs": [],
   "source": [
    "show_data_info(\n",
    "    train_dataset=train_tf_images_normalized,\n",
    "    valid_dataset=valid_tf_images_normalized\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1734,
     "status": "ok",
     "timestamp": 1730797822888,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "xDC76CT5OzRC",
    "outputId": "865afad9-5668-485a-b808-51730a1b4af3"
   },
   "outputs": [],
   "source": [
    "# Inspeksi data pada index tertentu\n",
    "inspector.inspect(\n",
    "    train_dataset=train_tf_images_normalized,\n",
    "    valid_dataset=valid_tf_images_normalized\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkCDc4d0O4vE"
   },
   "source": [
    "#### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 917,
     "status": "ok",
     "timestamp": 1730797823800,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "xsPepm4VO0rR"
   },
   "outputs": [],
   "source": [
    "train_tf_images_augmented, valid_tf_images_augmented = preprocessor.image_augmentation(\n",
    "    train_data=train_tf_images_normalized,\n",
    "    valid_data=valid_tf_images_normalized\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1730797823801,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "ld_mOuIdO6IC",
    "outputId": "fdafef92-5666-4804-ddda-dbcb944d86f1"
   },
   "outputs": [],
   "source": [
    "show_data_info(\n",
    "    train_dataset=train_tf_images_augmented,\n",
    "    valid_dataset=valid_tf_images_augmented\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3547,
     "status": "ok",
     "timestamp": 1730797827341,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "dfYA_OlYO7MY",
    "outputId": "478d398a-f191-4d6e-b47e-900155b0dbbb"
   },
   "outputs": [],
   "source": [
    "# Inspeksi data pada index tertentu\n",
    "inspector.inspect(\n",
    "    train_dataset=train_tf_images_augmented,\n",
    "    valid_dataset=valid_tf_images_augmented\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CD5hDFppPFEW"
   },
   "source": [
    "##### Apakah data dapat teraugmentasi dengan menggunakan class preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1730797827342,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "ogiX5ftwO8Su"
   },
   "outputs": [],
   "source": [
    "# Konversi gambar PIL ke tensor TensorFlow\n",
    "def convert_to_tensor(image):\n",
    "    image = np.array(image)\n",
    "    image = tf.cast(image / 255., tf.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "executionInfo": {
     "elapsed": 4013,
     "status": "ok",
     "timestamp": 1730797831345,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "WroWgMZJPGnY",
    "outputId": "110697d0-7fbd-46a9-9456-d993f65e8997"
   },
   "outputs": [],
   "source": [
    "sample_train_image_tensor = convert_to_tensor(train_image)\n",
    "sample_valid_image_tensor = convert_to_tensor(valid_image)\n",
    "\n",
    "# Augmentasi gambar\n",
    "augmented_train_image, _ = preprocessor._augment_image(sample_train_image_tensor)\n",
    "augmented_valid_image, _ = preprocessor._augment_image(sample_valid_image_tensor)\n",
    "\n",
    "\n",
    "# Plot gambar asli dan hasil augmentasi\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Gambar asli\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Original Train Image')\n",
    "plt.imshow(train_image)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Original Valid Image')\n",
    "plt.imshow(valid_image)\n",
    "\n",
    "# Gambar augmentasi\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title('Augmented Train Image')\n",
    "plt.imshow(augmented_train_image)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title('Augmented Valid Image')\n",
    "plt.imshow(augmented_valid_image)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5Zmt8T4Qt3x"
   },
   "source": [
    "## Step 4. Quality Check (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pitxubhXQv7o"
   },
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1730797831346,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "HsFtTIZKQuVw"
   },
   "outputs": [],
   "source": [
    "def show_multiple_images_in_tf_data(dataset, n_skip, num_images, figsize_per_image=(3, 3), classes_list=None):\n",
    "    \"\"\"\n",
    "    Menampilkan beberapa gambar dari dataset TensorFlow dalam bentuk grid.\n",
    "\n",
    "    Args:\n",
    "        dataset (tf.data.Dataset): Dataset TensorFlow yang berisi gambar dan label.\n",
    "        n_skip (int): Jumlah elemen yang akan dilewati sebelum mengambil gambar untuk ditampilkan.\n",
    "        num_images (int): Jumlah gambar yang ingin ditampilkan.\n",
    "        figsize_per_image (tuple, optional): Ukuran setiap gambar dalam plot. Default adalah (3, 3).\n",
    "        classes_list (list, optional): Daftar nama kelas yang digunakan untuk memberi judul pada gambar.\n",
    "                                       Harus memiliki panjang yang sama dengan jumlah kelas yang ada dalam dataset.\n",
    "\n",
    "    Returns:\n",
    "        None: Fungsi ini hanya menampilkan gambar dan tidak mengembalikan nilai.\n",
    "\n",
    "    Notes:\n",
    "        - Jika dataset berisi pasangan (image, label), label akan digunakan untuk memberi judul pada gambar.\n",
    "        - Jika dataset hanya berisi gambar, judul tidak akan ditampilkan.\n",
    "        - Fungsi ini akan mengabaikan gambar yang memiliki lebih dari dua dimensi dengan cara mengurangi dimensi tambahan jika ada.\n",
    "        - Ukuran dari keseluruhan grid ditentukan berdasarkan jumlah gambar yang akan ditampilkan, sehingga akan terorganisir dalam beberapa baris dan kolom.\n",
    "    \"\"\"\n",
    "    dataset = dataset.skip(n_skip).take(num_images)\n",
    "\n",
    "    num_columns = math.ceil(math.sqrt(num_images))\n",
    "    num_rows = math.ceil(num_images / num_columns)\n",
    "    figsize = (num_columns * figsize_per_image[0], num_rows * figsize_per_image[1])\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    for idx, data in enumerate(dataset):\n",
    "        if len(data) == 2:\n",
    "            image, label = data\n",
    "        else:\n",
    "            image = data\n",
    "            label = None\n",
    "\n",
    "        image = image.numpy()\n",
    "\n",
    "        if image.ndim == 2:\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "        plt.subplot(num_rows, num_columns, idx + 1)\n",
    "        plt.imshow(np.squeeze(image), cmap='gray')\n",
    "\n",
    "        if label is not None:\n",
    "            plt.title(classes_list[label])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLn3LTIsQ0aR"
   },
   "source": [
    "### main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "executionInfo": {
     "elapsed": 2804,
     "status": "ok",
     "timestamp": 1730797834140,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "3hhg9pezQ2iw",
    "outputId": "4adffef3-836b-48dc-dc6e-7ac239a23b70"
   },
   "outputs": [],
   "source": [
    "show_multiple_images_in_tf_data(\n",
    "    train_tf_images_augmented,\n",
    "    n_skip=1,\n",
    "    num_images=12,\n",
    "    classes_list=LABEL_LIST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "executionInfo": {
     "elapsed": 3972,
     "status": "ok",
     "timestamp": 1730797838103,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "gxrzyEWsQ8Ld",
    "outputId": "474f7840-1429-4f3e-ce0f-d832b335e3ee"
   },
   "outputs": [],
   "source": [
    "show_multiple_images_in_tf_data(\n",
    "    valid_tf_images_augmented,\n",
    "    n_skip=80,\n",
    "    num_images=12,\n",
    "    classes_list=LABEL_LIST\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GFVS9ZXRBLS"
   },
   "source": [
    "# SAVING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8q2hQDuREAs"
   },
   "source": [
    "Proses ini kemungkinan akan memakan waktu lama, tergantun jumlah data dan dimensi gambar atau fitur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1730797838103,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "Ce9oA03RQ90O"
   },
   "outputs": [],
   "source": [
    "train_tf_images_augmented = train_tf_images_augmented.cache()\n",
    "valid_tf_images_augmented = valid_tf_images_augmented.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 79762,
     "status": "ok",
     "timestamp": 1730797917858,
     "user": {
      "displayName": "Angga Dwi Sunarto",
      "userId": "09566375417846211648"
     },
     "user_tz": -420
    },
    "id": "_I1x766vRDDz"
   },
   "outputs": [],
   "source": [
    "train_tf_images_augmented.save(TRAIN_TFRECOARD_PATH, compression=\"GZIP\")\n",
    "valid_tf_images_augmented.save(VALID_TFRECORD_PATH, compression=\"GZIP\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
